
# 1️⃣ Install required libraries

!pip install -q transformers datasets evaluate rouge_score accelerate torch

# Optional: Download NLTK data for tokenization (needed for ROUGE)
import nltk
nltk.download('punkt')


# 2️⃣ Import libraries

import torch
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from datasets import load_dataset
import evaluate
import textwrap


# 3️⃣ Device setup

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)


# 4️⃣ Load dataset (CNN/DailyMail small sample)

dataset = load_dataset("cnn_dailymail", "3.0.0", split="validation[:50]")
articles = dataset['article']
highlights = dataset['highlights']


# 5️⃣ Load pretrained model & tokenizer

MODEL_NAME = "facebook/bart-large-cnn"  # can change to "t5-small"
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).half().to(device).eval()
MAX_INPUT_LEN = model.config.max_position_embeddings - 3


# 6️⃣ Define summarization functions

@torch.inference_mode()
def summarize_gpu(texts, max_len=120, min_len=40):
    enc = tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=MAX_INPUT_LEN,
        return_tensors="pt"
    )
    enc = {k: v[:, :MAX_INPUT_LEN].to(device) for k, v in enc.items()}
    gen_ids = model.generate(
        **enc,
        max_length=max_len,
        min_length=min_len,
        no_repeat_ngram_size=3,
        early_stopping=True
    )
    return tokenizer.batch_decode(gen_ids, skip_special_tokens=True)

def summarise_many(text_list, max_len=140, min_len=50, batch_size=4):
    results = []
    for i in range(0, len(text_list), batch_size):
        results.extend(summarize_gpu(text_list[i:i+batch_size], max_len, min_len))
    return results


# 7️⃣ Generate summaries

predictions = summarise_many(articles, batch_size=2)

# Print first 3 summaries nicely
for i in range(3):
    print(f"\nArticle {i+1} summary:")
    print(textwrap.fill(predictions[i], width=100))


# 8️⃣ Evaluate using ROUGE

rouge = evaluate.load("rouge")
scores = rouge.compute(predictions=predictions, references=highlights, use_stemmer=True)
# Scale scores for readability
scores = {k: round(v*100,2) for k,v in scores.items()}
print("\nROUGE Scores:", scores)
